--load input file from HDFS
inputFile = LOAD 'hdfs:///user/root/file01.txt' AS (line);
-- Tokeize each word in the file (Map)
words = FOREACH inputFile GENERATE FLATTEN(TOKENIZE(line)) AS word;
-- Combine the words from the above stage
grpd = GROUP words BY word;
-- Count the occurence of each word (Reduce)
cntd = FOREACH grpd GENERATE group, COUNT(words);
-- Store the result in HDFS
STORE cntd INTO 'hdfs:///user/root/results1';

root@5744b585f922:/# hdfs dfs -cat /user/root/results1/part-r-00000
Bye     1
Hello   1
World   2
        0

