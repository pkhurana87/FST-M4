hive> CREATE TABLE episodeV (name STRING, line STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' TBLPROPERTIES ("skip.header.line.count"="2");
OK
Time taken: 0.156 seconds
hive> LOAD DATA LOCAL INPATH '/epi5.txt' INTO TABLE episodeV;
Loading data to table default.episodev
OK
Time taken: 0.326 seconds
hive> SELECT name, COUNT(name) AS no_of_lines from episodeV GROUP BY name ORDER BY no_of_lines;
Query ID = root_20211208092942_225be481-6790-461d-a8b0-408b7b595786
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1638415902056_0045, Tracking URL = http://90f05189a960:8088/proxy/application_1638415902056_0045/
Kill Command = /usr/local/hadoop/bin/mapred job  -kill job_1638415902056_0045
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2021-12-08 09:29:57,643 Stage-1 map = 0%,  reduce = 0%
2021-12-08 09:30:08,942 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 7.02 sec
2021-12-08 09:30:17,486 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 11.82 sec
MapReduce Total cumulative CPU time: 11 seconds 820 msec
Ended Job = job_1638415902056_0045
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1638415902056_0046, Tracking URL = http://90f05189a960:8088/proxy/application_1638415902056_0046/
Kill Command = /usr/local/hadoop/bin/mapred job  -kill job_1638415902056_0046
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2021-12-08 09:30:41,056 Stage-2 map = 0%,  reduce = 0%
2021-12-08 09:30:50,988 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 3.84 sec
2021-12-08 09:31:03,077 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 11.87 sec
MapReduce Total cumulative CPU time: 11 seconds 870 msec
Ended Job = job_1638415902056_0046
MapReduce Jobs Launched:
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 11.82 sec   HDFS Read: 61922 HDFS Write: 1529 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 11.87 sec   HDFS Read: 9035 HDFS Write: 1333 SUCCESS
Total MapReduce CPU Time Spent: 23 seconds 690 msec
OK
FIRST CONTROLLER        1
ASSISTANT OFFICER       1
WOMAN CONTROLLER        1
CAPTAIN 1
STRANGE VOICE   1
SECOND THREEPIO 1
SECOND OFFICER  1
SECOND CONTROLLER       1
REBEL FIGHTER   1
REBEL CAPTAIN   1
PILOTS  1
PILOT   1
OFFICER 1
MAN'S VOICE     1
IMPERIAL SOLDIER        1
HOBBIE  1
HEAD CONTROLLER 1
LIEUTENANT      2
TRACKING OFFICER        2
IMPERIAL OFFICER        2
MEDICAL DROID   2
SENIOR CONTROLLER       2
COMMUNICATIONS OFFICER  2
INTERCOM VOICE  2
DERLIN  3
TRENCH OFFICER  3
ANNOUNCER       3
CONTROLLER      3
BEN'S VOICE     4
DACK    4
JANSON  4
BOBA FETT       4
OZZEL   5
EMPEROR 5
NEEDA   5
ZEV     6
DECK OFFICER    7
VEERS   7
WEDGE   8
BEN     11
RIEEKAN 13
CREATURE        21
PIETT   23
YODA    36
VADER   56
LANDO   61
THREEPIO        92
LEIA    114
LUKE    127
HAN     181
Time taken: 84.466 seconds, Fetched: 50 row(s)